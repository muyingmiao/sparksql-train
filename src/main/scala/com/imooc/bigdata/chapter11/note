
Hadoop、Hive、Spark、Flink、Storm、Scala  其实都是大数据开发必备的技术/框架
    项目：以功能为主  中小公司/大公司
    平台：大公司  提供给用户通用/定制化的解决方案
        数据采集
        离线计算
        实时计算
        机器学习
        图计算
        ......



为什么要构建大数据云平台
    1）统一管控
        数据分散、异构 ==> 信息孤岛
        数据的存储、资源  ==> 统一的资源管控 造成资源浪费
    2）能力
        运维、支撑程度
        性能、规模瓶颈

    ==>
    数据湖：数据和资源的共享
    云能力：集群、扩容、快速开发


大数据云平台所涉及到的常见的功能


存储和计算：大数据的思想 ==> Hadoop
    公有云
        多租户 多用户
        ==> 数据安全
            ==> 不同的租户或者用户登录到系统之后，能访问的数据的权限是不一样
                ==> Table： 行  列
                    ==> 数据权限控制到行和列级别
            ==> 使用的资源也是不一样的  queue
    私有云


    有多个集群：热 冷 备份
        数据迁移  自动、压缩
        计算能力能否无缝对接  √

    隔离：队列隔离、资源隔离



资源分配如何最优、资源使用率最大化
    Spark/Flink
        spark-submit   多少executor、每个executor多少memory、每个executor多少core？

    调度框架：AZ、Oozie、crontab
        一个作业涉及多个Job：workflow
        多个job之间如何做资源隔离

    Spark/Flink on YARN：申请资源是需要一定的时间的，调优使得申请资源的时间减少！
        10分钟：2分钟+8分钟    30秒+9分30秒




兼容性角度
    Apache Hadoop
    CDH  Cloudera Manager
    HDP
    MapR
    华为：Huawei Manager    FusionInsight
    阿里
    腾讯
    百度
    ...


    假设数据平台是基于CDH/HDP来构建的
        但是：用户现在已有的数据是基于阿里、华为云来开发和运维的

    务必要提前做一件事情：熟悉已有的数据平台的一些功能 vs 我们数据平台的功能
        数据存储：CarbonData
        调度：oozie ==>  PK调度






引擎的适配
    离线：Spark Flink
    做一个功能：按照我们的产品设计文档，写一份代码，可以同时运行在不同的引擎上
        √Spark
        √Flink
    Apache Beam


运行方式的适配
    √YARN
    √K8S(Docker)



Spark和Flink的选择性问题
    Spark到现在社区是比较成熟、提供的功能也是比较完善的
    Flink 实时部分

    活到老学到老

    学习肯定是以案例进行展开   源码 测试用例

    大数据全栈

    很多人学习看不起wc：都是wc的变种

























