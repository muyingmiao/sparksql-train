一：资源设置
    core  memory executor-num
    executor  driver

    1）--executor-memory MEM    1G        每个executor的内存大小
        Cache
        shuffle
        task

    2）--executor-cores NUM     1         每个executor的cpu core数量
        4exe *  2core = 8个
        4exe *  4core = 16个

    3）--num-executors          2         executor的数量
        4exe *  2core = 8个
        8exe *  2core = 16个

        100task  ？ * 2 ？

    4）--queue                  root.用户名   运行的队列

${SPARK_HOME}/bin/spark-submit --class xxxx \
master yarn \
--deploy-mode cluster \
--executor-cores ? \
--num-executors ? \
--executor-memory ? \
application.jar xxx  yyy  zzz




二：广播变量在Spark中的使用

50exe  1000task

val params = ...  // 10M
val rdd = ...
rdd.foreach(x=>{...params...})

1000task * 10M = 10G
50exe * 10M = 500M

作业题： ETL处理中日志 join ip这个功能结合我们讲解的广播变量的原理及实现 重构我们的ETL实现逻辑



三：Shuffle调优
    map端缓冲区大小 : spark.shuffle.file.buffer	--conf key=value
        如果过小 ==> 数据频繁写入磁盘文件

    reduce端拉取数据缓冲区大小: spark.reducer.maxSizeInFlight

    reduce端拉取数据重试次数：spark.shuffle.io.maxRetries

    reduce端拉取数据等待间隔：spark.shuffle.io.retryWait



四：JVM相关
    对象==>eden 和其中一个survivor0区  此时另外一个survivor1是空

    eden + survivor0 满 ==> minor gc
        ==> survivor1
        8:1:1

    old enough or Survivor2 is full ==> old ==> full gc

    stop the world

    个人建议在生产上优先使用CMS G1     JDK8


   file not found/ file lost / timeout

   调节连接等待时长
   spark.core.connection.ack.wait.timeout


   调节executor堆外内存 spark.yarn.executor.memoryOverhead  1~2G之间
   executor lost、oom、shuffle output file cannot find
   300M


   spark-submit时通过--conf 把我们讲解的这些参数一一设置进去即可


   内存  统一内存管理方式（可以借的）  静态管理方式（固定）




